# Smart Healthcare Data Engineering Pipeline (PySpark)

A complete **Healthcare Analytics Data Engineering Pipeline** built using **PySpark** and the **Medallion Architecture (Bronze â†’ Silver â†’ Gold)**.

This project processes raw hospital patient visit records from CSV, cleans and transforms them into Parquet format, models the data into a Star Schema, and generates key healthcare business insights through Spark analytics queries.

It is designed as a **portfolio-quality Data Engineering project** demonstrating real-world ETL workflows, scalable data lake design, and analytics-ready outputs.

---

## ğŸš€ Project Overview

Healthcare organizations generate large volumes of patient visit data every day.  
To support reporting, analytics, and decision-making, raw transactional records must be transformed into clean, structured datasets.

This pipeline performs:

- Raw data ingestion into a Data Lake (Bronze)
- Data cleaning and enrichment (Silver)
- Star Schema modeling for analytics (Gold)
- KPI queries for hospital insights

---

## ğŸ— Pipeline Architecture (Medallion Design)

```
Raw CSV Patient Visit Data
        â†“
Bronze Layer (Raw Parquet)
        â†“
Silver Layer (Clean + Standardized Parquet)
        â†“
Gold Layer (Star Schema Tables)
        â†“
Business Queries + Healthcare KPI Reports
```

---

## ğŸ“‚ Project Structure

```
healthcare_data_pipeline/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ patient_visits.csv
â”‚
â”œâ”€â”€ jobs/
â”‚   â”œâ”€â”€ bronze_ingestion.py
â”‚   â”œâ”€â”€ silver_cleaning.py
â”‚   â”œâ”€â”€ gold_star_schema.py
â”‚   â””â”€â”€ business_queries.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ spark_session.py
â”‚   â”œâ”€â”€ schema_definitions.py
â”‚   â””â”€â”€ helpers.py
â”‚
â””â”€â”€ output/
    â”œâ”€â”€ bronze/
    â”œâ”€â”€ silver/
    â”œâ”€â”€ gold/
    â””â”€â”€ reports/
```

---

## ğŸ“Œ Data Source

The pipeline uses a sample dataset:

`data/patient_visits.csv`

Example:

```csv
visit_id,patient_id,patient_name,doctor_id,doctor_name,department,diagnosis,cost,visit_date,hospital_city
201,P001,John Smith,D101,Dr. Lee,Cardiology,Heart Checkup,500,2025-01-05,New York
202,P002,Amina Rahman,D102,Dr. Kim,Neurology,Migraine,300,2025-01-07,Boston
203,P003,Sarah Lee,D101,Dr. Lee,Cardiology,ECG Test,700,2025-01-10,New York
```

---

## âš™ï¸ Technologies Used

- **Python**
- **PySpark**
- **Parquet Storage Format**
- **Medallion Data Lake Architecture**
- **Star Schema Modeling**
- **Healthcare KPI Analytics Queries**

---

## ğŸš€ Pipeline Jobs

---

### ğŸ¥‰ Bronze Layer: Raw Data Ingestion

**File:** `jobs/bronze_ingestion.py`

Responsibilities:

- Read raw CSV patient visit data
- Apply schema validation
- Store raw records in Parquet format

Output:

```
output/bronze/
```

---

### ğŸ¥ˆ Silver Layer: Data Cleaning & Transformation

**File:** `jobs/silver_cleaning.py`

Transformations applied:

- Remove duplicate visit records
- Handle missing values
- Convert visit_date into proper DateType
- Rename cost field into visit_cost for clarity

Output:

```
output/silver/
```

---

### ğŸ¥‡ Gold Layer: Star Schema Modeling

**File:** `jobs/gold_star_schema.py`

Creates analytics-ready tables:

#### Dimension Tables
- `dim_patient`
- `dim_doctor`

#### Fact Table
- `fact_visits`

Output:

```
output/gold/
   â”œâ”€â”€ dim_patient/
   â”œâ”€â”€ dim_doctor/
   â””â”€â”€ fact_visits/
```

---

### ğŸ“Š Business Queries & Healthcare KPIs

**File:** `jobs/business_queries.py`

Key business insights generated:

- Revenue by Department
- Most Common Diagnoses
- City-wise Treatment Costs

Example:

```
Cardiology â†’ $1200
Neurology  â†’ $300
Orthopedics â†’ $400
```

---
